import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
import os

# =====================
# 1. Load Dataset
# =====================
df = pd.read_csv("tourism_final.csv")  # <-- update path accordingly

# =====================
# 2. Define Features & Target
# =====================
target = 'tourist_count'  # Update if classification task
target = target.strip()
features = [col for col in df.columns if col != target]

X = df[features]
y = df[target]

# Split dataset
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# =====================
# 3. Train Baseline Models
# =====================
model = None

if y.dtype.kind in 'ifu':
    # Regression Baselines
    print("\n=== Regression Baselines ===")

    # Linear Regression
    lr = LinearRegression()
    lr.fit(X_train, y_train)
    preds = lr.predict(X_val)
    print("LinearRegression:",
          "MAE=", mean_absolute_error(y_val, preds),
          "RMSE=", np.sqrt(mean_squared_error(y_val, preds)),
          "R2=", r2_score(y_val, preds))

    # Decision Tree Regressor
    dt = DecisionTreeRegressor(random_state=42)
    dt.fit(X_train, y_train)
    preds = dt.predict(X_val)
    print("DecisionTreeRegressor:",
          "MAE=", mean_absolute_error(y_val, preds),
          "RMSE=", np.sqrt(mean_squared_error(y_val, preds)),
          "R2=", r2_score(y_val, preds))

    # Save best performing model (example: DecisionTree)
    model = dt

else:
    # Classification Baselines
    print("\n=== Classification Baselines ===")

    # Logistic Regression
    log_reg = LogisticRegression(max_iter=1000)
    log_reg.fit(X_train, y_train)
    preds = log_reg.predict(X_val)
    print("LogisticRegression:",
          "Accuracy=", accuracy_score(y_val, preds),
          "Precision=", precision_score(y_val, preds, average='weighted'),
          "Recall=", recall_score(y_val, preds, average='weighted'),
          "F1=", f1_score(y_val, preds, average='weighted'))

    # Decision Tree Classifier
    dt_clf = DecisionTreeClassifier(random_state=42)
    dt_clf.fit(X_train, y_train)
    preds = dt_clf.predict(X_val)
    print("DecisionTreeClassifier:",
          "Accuracy=", accuracy_score(y_val, preds),
          "Precision=", precision_score(y_val, preds, average='weighted'),
          "Recall=", recall_score(y_val, preds, average='weighted'),
          "F1=", f1_score(y_val, preds, average='weighted'))

    # Save best performing model (example: DecisionTree)
    model = dt_clf

# =====================
# 4. Save Model Prototype
# =====================
os.makedirs("ml_models", exist_ok=True)
model_path = os.path.join("ml_models", "baseline_model.pkl")
if model:
    joblib.dump(model, model_path)
    print(f"\nâœ… Baseline model saved at: {model_path}")

# =====================
# 5. Final Test Evaluation
# =====================
if model:
    print("\n=== Test Set Evaluation ===")
    test_preds = model.predict(X_test)

    if y.dtype.kind in 'ifu':
        print("Test Results:",
              "MAE=", mean_absolute_error(y_test, test_preds),
              "RMSE=", np.sqrt(mean_squared_error(y_test, test_preds)),
              "R2=", r2_score(y_test, test_preds))
    else:
        print("Test Results:",
              "Accuracy=", accuracy_score(y_test, test_preds),
              "Precision=", precision_score(y_test, test_preds, average='weighted'),
              "Recall=", recall_score(y_test, test_preds, average='weighted'),
              "F1=", f1_score(y_test, test_preds, average='weighted'))
