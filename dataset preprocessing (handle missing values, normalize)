import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler
import os

# Paths
raw_path = "./datasets/raw/"
processed_path = "./datasets/processed/"

# Ensure processed folder exists
os.makedirs(processed_path, exist_ok=True)

# Example: loop through all raw CSVs
for file in os.listdir(raw_path):
    if file.endswith(".csv"):
        print(f"Processing {file}...")
        df = pd.read_csv(os.path.join(raw_path, file))

        # --- Handle Missing Values ---
        # Numeric: replace NaN with median
        num_cols = df.select_dtypes(include=[np.number]).columns
        imputer_num = SimpleImputer(strategy="median")
        df[num_cols] = imputer_num.fit_transform(df[num_cols])

        # Categorical: replace NaN with mode
        cat_cols = df.select_dtypes(exclude=[np.number]).columns
        imputer_cat = SimpleImputer(strategy="most_frequent")
        df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])

        # --- Normalize Numeric Columns ---
        scaler = MinMaxScaler()
        df[num_cols] = scaler.fit_transform(df[num_cols])

        # Save cleaned dataset
        df.to_csv(os.path.join(processed_path, f"processed_{file}"), index=False)

print("âœ… Preprocessing complete. Cleaned files saved to /datasets/processed/")
